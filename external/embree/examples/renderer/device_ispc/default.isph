// ======================================================================== //
// Copyright 2009-2013 Intel Corporation                                    //
//                                                                          //
// Licensed under the Apache License, Version 2.0 (the "License");          //
// you may not use this file except in compliance with the License.         //
// You may obtain a copy of the License at                                  //
//                                                                          //
//     http://www.apache.org/licenses/LICENSE-2.0                           //
//                                                                          //
// Unless required by applicable law or agreed to in writing, software      //
// distributed under the License is distributed on an "AS IS" BASIS,        //
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. //
// See the License for the specific language governing permissions and      //
// limitations under the License.                                           //
// ======================================================================== //

#ifndef __EMBREE_ISPC_DEFAULT_ISPH__
#define __EMBREE_ISPC_DEFAULT_ISPH__

#define LOG(x)

#ifndef NULL
#define NULL 0
#endif

typedef unsigned int uint;
typedef unsigned int uint32;

#include "api/ref.isph"
#include "../../../embree_ispc/math/math.isph"
#include "../../../embree_ispc/math/vec.isph"
#include "../../../embree_ispc/math/linearspace.isph"
#include "../../../embree_ispc/math/affinespace.isph"

#if defined(__MIC__)
inline void* uniform align_ptr(void* uniform ptr) {
  return (void* uniform) ((((uniform int64)ptr) + 63) & (-64));
}
#elif defined(__AVX__)
inline void* uniform align_ptr(void* uniform ptr) {
  return (void* uniform) ((((uniform int64)ptr) + 31) & (-32));
}
#else
inline void* uniform align_ptr(void* uniform ptr) {
  return (void* uniform) ((((uniform int64)ptr) + 16) & (-16));
}
#endif

#endif
